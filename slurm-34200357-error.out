You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Device set to use cpu
Device set to use cpu
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: pritamdeka/S-BioBert-snli-multinli-stsb
Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors
slurmstepd-gypsum-gpu081: error: *** JOB 34200357 ON gypsum-gpu081 CANCELLED AT 2025-05-13T00:26:10 ***
